{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "> How to search for and update tasks in Copper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from cu_api import core, config\n",
    "from cu_api.query import Query as _Query\n",
    "from cu_api.core import set_headers as _set_headers\n",
    "from cu_api.search import _search_loop, get_owners, search_over_field\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Copper Tasks\n",
    "\n",
    "A `Query` is an object that holds all of your search parameters and tells cu_api what you want from Copper. Once you create a query and give it to cu_api via the `tasks.search(Query)` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class Query(_Query):\n",
    "    pass\n",
    "\n",
    "def create_query(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Create and return a new Query object\n",
    "    \"\"\"\n",
    "    return _Query(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query info here\n",
    "blah Blah Blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _clean_row(row_data:list, #Returned company data as list of dictionaries,\n",
    "               cf_fields:list = [], # list of custom fields on companies you would like to include\n",
    "):\n",
    "    \"\"\"Process to clean returned copper data\"\"\"\n",
    "\n",
    "    core.prc_get_cf_fields()\n",
    "\n",
    "    custom_fields = getattr(config,'CUSTOM_FIELDS')\n",
    "    custom_fields_dict = getattr(config,'CUSTOM_FIELDS_DICT')\n",
    "    \n",
    "\n",
    "    def clean_date(date):\n",
    "        try:\n",
    "            if date is None:\n",
    "                return None  # Handle None values (empty rows)\n",
    "\n",
    "            if isinstance(date, int) and len(str(date)) >= 6 and len(str(date)) <= 10:\n",
    "                # If it's an integer with <= 10 digits, assume it's a Unix timestamp\n",
    "                ct_timezone = pytz.timezone('US/Central')\n",
    "                new_date = pd.to_datetime(date, unit='s',utc=True).tz_convert(ct_timezone)\n",
    "                return new_date\n",
    "            else:\n",
    "                return date\n",
    "        except Exception as e:\n",
    "            return date\n",
    "\n",
    "    native_items = ['id', 'name', 'assignee_id','tags']\n",
    "\n",
    "    output_dict = {}\n",
    "    output_dict['related_id'] = row_data.get('related_resource').get('id',None)\n",
    "    output_dict['related_type'] = row_data.get('related_resource').get('type',None)\n",
    "    output_dict['due_date'] = clean_date(row_data['due_date'])\n",
    "    output_dict['reminder_date'] = clean_date(row_data['reminder_date'])\n",
    "    output_dict['completed_date'] = clean_date(row_data['completed_date'])\n",
    "\n",
    "    for item in native_items:\n",
    "        output_dict[item] = row_data.get(item, None)\n",
    "    \n",
    "    custom_field_data = row_data['custom_fields']\n",
    "\n",
    "    for dict_item in custom_field_data:\n",
    "        item_id = dict_item['custom_field_definition_id']\n",
    "        item_name = custom_fields_dict.get(item_id, None)\n",
    "        data_type = custom_fields[item_id].get('data_type')\n",
    "\n",
    "        if item_name not in cf_fields and item_id not in cf_fields or item_name is None:\n",
    "            continue\n",
    "        elif item_name is not None and ('options' in list(custom_fields[item_id].keys())):\n",
    "            item_value = dict_item['value']\n",
    "            value_name = core.cf_option_name(item_id,item_value)\n",
    "            output_dict[item_name] = value_name\n",
    "        elif data_type == 'Date':\n",
    "            cleaned_date = clean_date(dict_item['value'])\n",
    "            output_dict[item_name] = cleaned_date\n",
    "        else:\n",
    "            item_value = dict_item['value']\n",
    "            output_dict[item_name] = item_value\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def _clean_dataframe(df):\n",
    "    list_assign_ids = list(df['assignee_id'].dropna().unique().astype(int))\n",
    "    assignee_dict = get_owners(list_assign_ids)\n",
    "\n",
    "    df['Owned By'] = df['assignee_id'].apply(lambda value: assignee_dict.get(value))\n",
    "    df.drop(columns=['assignee_id'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "\n",
    "def set_headers(AccessToken:str, #Access Token (API Key) provided by Copper\n",
    "                 UserEmail:str): #Email associated with your API key\n",
    "    _set_headers(AccessToken,UserEmail)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def search(search_query,            # Instance of Query object\n",
    "            clean_data:bool = True, # Whether to clean results or not\n",
    "            drop:list = None,       # Columns to drop from final dataframe\n",
    "            **kwargs\n",
    "            )->pd.DataFrame:\n",
    "    \"\"\"Search for task records in Copper!\n",
    "    \n",
    "    This function allows you to systematically search Copper for tasks \n",
    "    that match the parameters specified in your `Query` and returns the \n",
    "    returns the data as a pandas dataframe\n",
    "\n",
    "    Supported standard fields for search: name, \n",
    "    \"\"\"\n",
    "    \n",
    "    if 'name' in search_query._native_fields:\n",
    "        combined_results, Outputs = search_over_field('name','https://api.copper.com/developer_api/v1/tasks/search',search_query)\n",
    "    else:\n",
    "        combined_results, Outputs = _search_loop(search_query= search_query, url= 'https://api.copper.com/developer_api/v1/tasks/search')\n",
    "    \n",
    "    # Custom Fields\n",
    "    if 'cf_fields' in kwargs:     cf_fields = kwargs.get('cf_fields')\n",
    "    else:                         cf_fields = Outputs\n",
    "\n",
    "    # Processing Rows:\n",
    "    cleaned_rows = []\n",
    "    for result in tqdm(combined_results,'Cleaning Data',total=len(combined_results)):\n",
    "        cleaned_rows.append(_clean_row(result, cf_fields))\n",
    "    \n",
    "    # To Clean, or not to Clean\n",
    "    if not clean_data:\n",
    "        print('Returning raw results')\n",
    "        return cleaned_rows\n",
    "\n",
    "    cleaned_rows_df = pd.DataFrame(cleaned_rows)\n",
    "    cleaned_data_df = _clean_dataframe(cleaned_rows_df)\n",
    "\n",
    "    if isinstance(drop,list):      return cleaned_data_df.drop(columns=drop,inplace=True)\n",
    "    else:                               return cleaned_data_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def update(df: pd.DataFrame, columns: list, cf_ids: list = None):\n",
    "    \"\"\"\n",
    "    Function to update companies in copper using a pandas DataFrame with a column of 'id' to identify\n",
    "    companies and a list of the columns you would like to update.\n",
    "    \n",
    "    Either pass in a list of custom field ids, or a list will be created using matching column names.\n",
    "    \"\"\"\n",
    "\n",
    "    if 'id' not in df.columns: raise \n",
    "\n",
    "    if cf_ids is None:\n",
    "        cf_ids = [reverse_cf_lookup.get(col) for col in columns if col in reverse_cf_lookup]\n",
    "        columns = [col for col in columns if col in reverse_cf_lookup]\n",
    "\n",
    "    df = df[columns + ['id']]\n",
    "    prepared_data = df.set_index('id').to_dict(orient='index')\n",
    "\n",
    "    total_companies = len(df['id'])\n",
    "    companies_updated = 0\n",
    "    max_size = 10\n",
    "    Sess = get_session(headers)\n",
    "\n",
    "    # Initialize the tqdm progress bar\n",
    "    progress_bar = tqdm(total=total_companies)\n",
    "\n",
    "    while companies_updated < total_companies:\n",
    "        current_batch_size = min(max_size, total_companies - companies_updated)\n",
    "        payload = []\n",
    "\n",
    "        # Loop to make `payload`\n",
    "        for idx in range(companies_updated, companies_updated + current_batch_size):\n",
    "            comp_id = int(df['id'].iloc[idx])\n",
    "\n",
    "            cf_data_list = [{'custom_field_definition_id': cf_id, 'value': prepared_data[comp_id][col]}\n",
    "                            for cf_id, col in zip(cf_ids, columns)]\n",
    "\n",
    "            company_json = {\"id\": comp_id, 'custom_fields': cf_data_list}\n",
    "            payload.append(company_json)\n",
    "\n",
    "        json_data = {\"companies\": payload}\n",
    "        request_sent = Sess.post('https://api.copper.com/developer_api/v1/companies/bulk_update', json=json_data)\n",
    "\n",
    "        if request_sent.status_code != 200:\n",
    "            print(request_sent.text)\n",
    "            break\n",
    "        else:\n",
    "            companies_updated += current_batch_size\n",
    "            progress_bar.update(current_batch_size)  # Update the progress bar\n",
    "\n",
    "    progress_bar.close()  # Close the progress bar when done\n",
    "    print('All companies updated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
